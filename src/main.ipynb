{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Machine Learning, aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparar datos, entrenar y evaluar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [1/5], Pérdida: 1.3885\n",
      "Época [2/5], Pérdida: 0.8181\n",
      "Época [3/5], Pérdida: 0.7927\n",
      "Época [4/5], Pérdida: 0.6196\n",
      "Época [5/5], Pérdida: 0.4855\n",
      "Exactitud de validación: 56.72%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# 1. Preparar los datos\n",
    "\n",
    "# Directorio que contiene las imágenes\n",
    "data_dir = \"../imagenes_entrenamiento\"\n",
    "\n",
    "# Tamaño de los lotes de datos\n",
    "batch_size = 8\n",
    "\n",
    "# Transformaciones que se aplican a las imágenes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Redimensionar las imágenes a 224x224 píxeles\n",
    "    transforms.ToTensor(),  # Convertir las imágenes a tensores\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalizar los colores\n",
    "])\n",
    "\n",
    "# Cargar las imágenes y asignar etiquetas automáticamente según los nombres de las carpetas\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y validación\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Crear cargadores de datos para el entrenamiento y la validación\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 2. Entrenar el modelo\n",
    "\n",
    "# Utilizar ResNet-18 preentrenada\n",
    "#model = models.resnet18(pretrained=True) --> Por esta linea daba warning\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Modificar la capa final para clasificar en 3 clases\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 3)\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Número de épocas de entrenamiento\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Establecer el modo de entrenamiento\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:  # Iterar sobre los lotes de datos\n",
    "        optimizer.zero_grad()  # Limpiar los gradientes\n",
    "        outputs = model(inputs)  # Hacer la predicción\n",
    "        loss = criterion(outputs, labels)  # Calcular la pérdida\n",
    "        loss.backward()  # Propagar hacia atrás\n",
    "        optimizer.step()  # Actualizar los parámetros\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Época [{epoch+1}/{num_epochs}], Pérdida: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 3. Evaluar el modelo\n",
    "\n",
    "model.eval()  # Establecer el modo de evaluación\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # Desactivar el cálculo de gradientes\n",
    "    for inputs, labels in val_loader:  # Iterar sobre los lotes de datos de validación\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)  # Obtener la clase con la mayor probabilidad\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f\"Exactitud de validación: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecir ya con el modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La persona en la imagen \"pasajero1.jpg\" tiene \"mucha\" ropa.\n",
      "La persona en la imagen \"pasajero2.webp\" tiene \"poca\" ropa.\n",
      "La persona en la imagen \"pasajero3.webp\" tiene \"mucha\" ropa.\n",
      "La persona en la imagen \"pasajero4.jpg\" tiene \"mucha\" ropa.\n",
      "La persona en la imagen \"pasajero5.webp\" tiene \"mucha\" ropa.\n",
      "La persona en la imagen \"pasajero6.webp\" tiene \"mucha\" ropa.\n",
      "La persona en la imagen \"pasajero7.jpg\" tiene \"poca\" ropa.\n",
      "La persona en la imagen \"pasajero8.jpg\" tiene \"mucha\" ropa.\n",
      "La persona en la imagen \"pasajero9.jpg\" tiene \"mucha\" ropa.\n",
      "La persona en la imagen \"pasajero10.jpg\" tiene \"mucha\" ropa.\n",
      "La persona en la imagen \"pasajero11.jpg\" tiene \"mucha\" ropa.\n",
      "La persona en la imagen \"pasajero12.jpg\" tiene \"poca\" ropa.\n",
      "La persona en la imagen \"pasajero13.jpg\" tiene \"poca\" ropa.\n",
      "La persona en la imagen \"pasajero14.jpg\" tiene \"poca\" ropa.\n",
      "La persona en la imagen \"pasajero15.jpg\" tiene \"mucha\" ropa.\n",
      "La persona en la imagen \"pasajero16.jpg\" tiene \"mucha\" ropa.\n",
      "La persona en la imagen \"pasajero17.jpg\" tiene \"mucha\" ropa.\n",
      "La persona en la imagen \"pasajero18.webp\" tiene \"mucha\" ropa.\n",
      "La persona en la imagen \"pasajero19.jpg\" tiene \"mucha\" ropa.\n",
      "La persona en la imagen \"pasajero20.jpg\" tiene \"poca\" ropa.\n",
      "La persona en la imagen \"pasajero21.jpg\" tiene \"poca\" ropa.\n",
      "La persona en la imagen \"pasajero22.jpg\" tiene \"poca\" ropa.\n",
      "La persona en la imagen \"pasajero23.webp\" tiene \"mucha\" ropa.\n",
      "La persona en la imagen \"pasajero24.jpg\" tiene \"poca\" ropa.\n",
      "La persona en la imagen \"pasajero25.webp\" tiene \"poca\" ropa.\n",
      "La persona en la imagen \"pasajero26.jpg\" tiene \"mucha\" ropa.\n",
      "La persona en la imagen \"pasajero27.jpg\" tiene \"poca\" ropa.\n",
      "La persona en la imagen \"pasajero28.jpg\" tiene \"poca\" ropa.\n",
      "La persona en la imagen \"pasajero29.jpg\" tiene \"poca\" ropa.\n",
      "La persona en la imagen \"pasajero30.jpg\" tiene \"mucha\" ropa.\n",
      "La persona en la imagen \"pasajero31.webp\" tiene \"poca\" ropa.\n",
      "La persona en la imagen \"pasajero32.webp\" tiene \"poca\" ropa.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# Función para generar un número aleatorio flotante de 2 dígitos dentro de un rango específico\n",
    "def generar_peso_extra(clase_ropa):\n",
    "    if clase_ropa == \"poca\":\n",
    "        return round(random.uniform(0, 1), 2)\n",
    "    elif clase_ropa == \"mediana\":\n",
    "        return round(random.uniform(1, 2), 2)\n",
    "    else:\n",
    "        return round(random.uniform(2, 4), 2)\n",
    "\n",
    "# Función para predecir la clase de ropa y actualizar el archivo de Excel\n",
    "def predict_images(excel_file):\n",
    "    \"\"\"Función para predecir la clase de todas las imágenes en un archivo de Excel.\"\"\"\n",
    "    # Cargar el archivo de Excel en un DataFrame\n",
    "    df = pd.read_excel(excel_file)\n",
    "\n",
    "    # Iterar sobre cada fila del DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        image_path = row[\"IMAGEN_PASAJERO\"]\n",
    "        if pd.notnull(image_path) and os.path.isfile(image_path):\n",
    "            # Verificar si la ruta es un archivo válido\n",
    "            image = Image.open(image_path)\n",
    "            image = transform(image).unsqueeze(0)\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                class_name = dataset.classes[predicted.item()]\n",
    "\n",
    "                # Este print luego hay que comentarlo\n",
    "                print(f'La persona en la imagen \"{os.path.basename(image_path)}\" tiene \"{class_name}\" ropa.')\n",
    "\n",
    "                # Generar el peso extra aleatorio según la clase de ropa\n",
    "                peso_extra = generar_peso_extra(class_name)\n",
    "\n",
    "                # Actualizar las columnas \"ROPA\" y \"PESO_EXTRA\" en el DataFrame\n",
    "                df.loc[index, \"ROPA\"] = class_name\n",
    "                df.loc[index, \"PESO_KG_EXTRA\"] = peso_extra\n",
    "\n",
    "    # Guardar los cambios en el archivo de Excel\n",
    "    df.to_excel(excel_file, index=False)\n",
    "\n",
    "# Ruta hacia la base de datos de los pasajeros\n",
    "predict_images(\"../pasajeros/bd_pasajeros.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
